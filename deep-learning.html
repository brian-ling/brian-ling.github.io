<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 20 Deep Learning | STAT 362 R for Data Science</title>
  <meta name="description" content="Notes for STAT 362" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 20 Deep Learning | STAT 362 R for Data Science" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Notes for STAT 362" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 20 Deep Learning | STAT 362 R for Data Science" />
  
  <meta name="twitter:description" content="Notes for STAT 362" />
  

<meta name="author" content="Brian Ling" />


<meta name="date" content="2022-03-29" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ensemble-methods.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">R for Data Science</a></li>

<li class="divider"></li>
<li><a href="index.html#syllabus">Syllabus<span></span></a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction<span></span></a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#what-is-r-and-rstudio"><i class="fa fa-check"></i><b>1.1</b> What is R and RStudio?<span></span></a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#what-will-you-learn-in-this-course"><i class="fa fa-check"></i><b>1.2</b> What will you learn in this course?<span></span></a><ul>
<li class="chapter" data-level="1.2.1" data-path="introduction.html"><a href="introduction.html#r-and-r-as-a-programming-language"><i class="fa fa-check"></i><b>1.2.1</b> R and R as a programming language<span></span></a></li>
<li class="chapter" data-level="1.2.2" data-path="introduction.html"><a href="introduction.html#data-wrangling"><i class="fa fa-check"></i><b>1.2.2</b> Data Wrangling<span></span></a></li>
<li class="chapter" data-level="1.2.3" data-path="introduction.html"><a href="introduction.html#data-visualization"><i class="fa fa-check"></i><b>1.2.3</b> Data Visualization<span></span></a></li>
<li class="chapter" data-level="1.2.4" data-path="introduction.html"><a href="introduction.html#statistical-inference"><i class="fa fa-check"></i><b>1.2.4</b> Statistical Inference<span></span></a></li>
<li class="chapter" data-level="1.2.5" data-path="introduction.html"><a href="introduction.html#machine-learning"><i class="fa fa-check"></i><b>1.2.5</b> Machine Learning<span></span></a></li>
<li class="chapter" data-level="1.2.6" data-path="introduction.html"><a href="introduction.html#some-numerical-methods"><i class="fa fa-check"></i><b>1.2.6</b> Some Numerical Methods<span></span></a></li>
<li class="chapter" data-level="1.2.7" data-path="introduction.html"><a href="introduction.html#lastly"><i class="fa fa-check"></i><b>1.2.7</b> Lastly<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#lets-get-started"><i class="fa fa-check"></i><b>1.3</b> Let’s Get Started<span></span></a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#r-data-structures"><i class="fa fa-check"></i><b>1.4</b> R Data Structures<span></span></a><ul>
<li class="chapter" data-level="1.4.1" data-path="introduction.html"><a href="introduction.html#vectors"><i class="fa fa-check"></i><b>1.4.1</b> Vectors<span></span></a></li>
<li class="chapter" data-level="1.4.2" data-path="introduction.html"><a href="introduction.html#factors"><i class="fa fa-check"></i><b>1.4.2</b> Factors<span></span></a></li>
<li class="chapter" data-level="1.4.3" data-path="introduction.html"><a href="introduction.html#matrix"><i class="fa fa-check"></i><b>1.4.3</b> Matrix<span></span></a></li>
<li class="chapter" data-level="1.4.4" data-path="introduction.html"><a href="introduction.html#lists"><i class="fa fa-check"></i><b>1.4.4</b> Lists<span></span></a></li>
<li class="chapter" data-level="1.4.5" data-path="introduction.html"><a href="introduction.html#data-frames"><i class="fa fa-check"></i><b>1.4.5</b> Data frames<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#operators"><i class="fa fa-check"></i><b>1.5</b> Operators<span></span></a><ul>
<li class="chapter" data-level="1.5.1" data-path="introduction.html"><a href="introduction.html#vectorized-operators"><i class="fa fa-check"></i><b>1.5.1</b> Vectorized Operators<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="introduction.html"><a href="introduction.html#built-in-functions"><i class="fa fa-check"></i><b>1.6</b> Built-in Functions<span></span></a><ul>
<li class="chapter" data-level="1.6.1" data-path="introduction.html"><a href="introduction.html#sort"><i class="fa fa-check"></i><b>1.6.1</b> <code>sort()</code><span></span></a></li>
<li class="chapter" data-level="1.6.2" data-path="introduction.html"><a href="introduction.html#seq"><i class="fa fa-check"></i><b>1.6.2</b> <code>seq()</code><span></span></a></li>
<li class="chapter" data-level="1.6.3" data-path="introduction.html"><a href="introduction.html#rep"><i class="fa fa-check"></i><b>1.6.3</b> <code>rep()</code><span></span></a></li>
<li class="chapter" data-level="1.6.4" data-path="introduction.html"><a href="introduction.html#pmax-pmin"><i class="fa fa-check"></i><b>1.6.4</b> <code>pmax</code>, <code>pmin</code><span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="introduction.html"><a href="introduction.html#some-useful-rstudio-shortcuts"><i class="fa fa-check"></i><b>1.7</b> Some Useful RStudio Shortcuts<span></span></a></li>
<li class="chapter" data-level="1.8" data-path="introduction.html"><a href="introduction.html#exercises"><i class="fa fa-check"></i><b>1.8</b> Exercises<span></span></a></li>
<li class="chapter" data-level="1.9" data-path="introduction.html"><a href="introduction.html#comments-to-exercises"><i class="fa fa-check"></i><b>1.9</b> Comments to Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>2</b> Probability<span></span></a><ul>
<li class="chapter" data-level="2.1" data-path="probability.html"><a href="probability.html#probability-distributions"><i class="fa fa-check"></i><b>2.1</b> Probability Distributions<span></span></a><ul>
<li class="chapter" data-level="2.1.1" data-path="probability.html"><a href="probability.html#common-distributions"><i class="fa fa-check"></i><b>2.1.1</b> Common Distributions<span></span></a></li>
<li class="chapter" data-level="2.1.2" data-path="probability.html"><a href="probability.html#exercises-1"><i class="fa fa-check"></i><b>2.1.2</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="probability.html"><a href="probability.html#simulation"><i class="fa fa-check"></i><b>2.2</b> Simulation<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="programming-in-r.html"><a href="programming-in-r.html"><i class="fa fa-check"></i><b>3</b> Programming in R<span></span></a><ul>
<li class="chapter" data-level="3.1" data-path="programming-in-r.html"><a href="programming-in-r.html#writing-functions-in-r"><i class="fa fa-check"></i><b>3.1</b> Writing functions in R<span></span></a></li>
<li class="chapter" data-level="3.2" data-path="programming-in-r.html"><a href="programming-in-r.html#control-flow"><i class="fa fa-check"></i><b>3.2</b> Control Flow<span></span></a><ul>
<li class="chapter" data-level="3.2.1" data-path="programming-in-r.html"><a href="programming-in-r.html#for-loop"><i class="fa fa-check"></i><b>3.2.1</b> for loop<span></span></a></li>
<li class="chapter" data-level="3.2.2" data-path="programming-in-r.html"><a href="programming-in-r.html#while-loop"><i class="fa fa-check"></i><b>3.2.2</b> while loop<span></span></a></li>
<li class="chapter" data-level="3.2.3" data-path="programming-in-r.html"><a href="programming-in-r.html#if-cond"><i class="fa fa-check"></i><b>3.2.3</b> if (cond)<span></span></a></li>
<li class="chapter" data-level="3.2.4" data-path="programming-in-r.html"><a href="programming-in-r.html#if-cond-else-expr"><i class="fa fa-check"></i><b>3.2.4</b> if (cond) else expr<span></span></a></li>
<li class="chapter" data-level="3.2.5" data-path="programming-in-r.html"><a href="programming-in-r.html#if-else-ladder"><i class="fa fa-check"></i><b>3.2.5</b> If else ladder<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="programming-in-r.html"><a href="programming-in-r.html#automatically-reindent-code"><i class="fa fa-check"></i><b>3.3</b> Automatically Reindent Code<span></span></a></li>
<li class="chapter" data-level="3.4" data-path="programming-in-r.html"><a href="programming-in-r.html#speed-consideration"><i class="fa fa-check"></i><b>3.4</b> Speed Consideration<span></span></a></li>
<li class="chapter" data-level="3.5" data-path="programming-in-r.html"><a href="programming-in-r.html#another-simulation-example"><i class="fa fa-check"></i><b>3.5</b> Another Simulation Example<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="creating-some-basic-plots.html"><a href="creating-some-basic-plots.html"><i class="fa fa-check"></i><b>4</b> Creating Some Basic Plots<span></span></a><ul>
<li class="chapter" data-level="4.1" data-path="creating-some-basic-plots.html"><a href="creating-some-basic-plots.html#scatter-plot"><i class="fa fa-check"></i><b>4.1</b> Scatter Plot<span></span></a></li>
<li class="chapter" data-level="4.2" data-path="creating-some-basic-plots.html"><a href="creating-some-basic-plots.html#line-graph"><i class="fa fa-check"></i><b>4.2</b> Line Graph<span></span></a></li>
<li class="chapter" data-level="4.3" data-path="creating-some-basic-plots.html"><a href="creating-some-basic-plots.html#bar-chart"><i class="fa fa-check"></i><b>4.3</b> Bar Chart<span></span></a></li>
<li class="chapter" data-level="4.4" data-path="creating-some-basic-plots.html"><a href="creating-some-basic-plots.html#histogram"><i class="fa fa-check"></i><b>4.4</b> Histogram<span></span></a></li>
<li class="chapter" data-level="4.5" data-path="creating-some-basic-plots.html"><a href="creating-some-basic-plots.html#box-plot"><i class="fa fa-check"></i><b>4.5</b> Box Plot<span></span></a></li>
<li class="chapter" data-level="4.6" data-path="creating-some-basic-plots.html"><a href="creating-some-basic-plots.html#plotting-a-function-curve"><i class="fa fa-check"></i><b>4.6</b> Plotting a function curve<span></span></a></li>
<li class="chapter" data-level="4.7" data-path="creating-some-basic-plots.html"><a href="creating-some-basic-plots.html#more-on-plots-with-base-r"><i class="fa fa-check"></i><b>4.7</b> More on plots with base R<span></span></a><ul>
<li class="chapter" data-level="4.7.1" data-path="creating-some-basic-plots.html"><a href="creating-some-basic-plots.html#multi-frame-plot"><i class="fa fa-check"></i><b>4.7.1</b> Multi-frame plot<span></span></a></li>
<li class="chapter" data-level="4.7.2" data-path="creating-some-basic-plots.html"><a href="creating-some-basic-plots.html#subsubsec:type_of_plot"><i class="fa fa-check"></i><b>4.7.2</b> Type of Plot<span></span></a></li>
<li class="chapter" data-level="4.7.3" data-path="creating-some-basic-plots.html"><a href="creating-some-basic-plots.html#parameters-of-a-plot"><i class="fa fa-check"></i><b>4.7.3</b> Parameters of a plot<span></span></a></li>
<li class="chapter" data-level="4.7.4" data-path="creating-some-basic-plots.html"><a href="creating-some-basic-plots.html#elements-on-plot"><i class="fa fa-check"></i><b>4.7.4</b> Elements on plot<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="creating-some-basic-plots.html"><a href="creating-some-basic-plots.html#summary-of-ggplot"><i class="fa fa-check"></i><b>4.8</b> Summary of <code>ggplot</code><span></span></a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="managing-data-with-r.html"><a href="managing-data-with-r.html"><i class="fa fa-check"></i><b>5</b> Managing Data with R<span></span></a><ul>
<li class="chapter" data-level="5.1" data-path="managing-data-with-r.html"><a href="managing-data-with-r.html#missing-values"><i class="fa fa-check"></i><b>5.1</b> Missing Values<span></span></a></li>
<li class="chapter" data-level="5.2" data-path="managing-data-with-r.html"><a href="managing-data-with-r.html#saving-loading-and-removing-r-data-structures"><i class="fa fa-check"></i><b>5.2</b> Saving, loading, and removing R data structures<span></span></a></li>
<li class="chapter" data-level="5.3" data-path="managing-data-with-r.html"><a href="managing-data-with-r.html#importing-and-saving-data-from-csv-files"><i class="fa fa-check"></i><b>5.3</b> Importing and saving data from CSV files<span></span></a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="review-chapter-1-5.html"><a href="review-chapter-1-5.html"><i class="fa fa-check"></i><b>6</b> Review (Chapter 1-5)<span></span></a><ul>
<li class="chapter" data-level="6.1" data-path="review-chapter-1-5.html"><a href="review-chapter-1-5.html#simulation-1"><i class="fa fa-check"></i><b>6.1</b> Simulation<span></span></a></li>
<li class="chapter" data-level="6.2" data-path="review-chapter-1-5.html"><a href="review-chapter-1-5.html#matrix-1"><i class="fa fa-check"></i><b>6.2</b> Matrix<span></span></a></li>
<li class="chapter" data-level="6.3" data-path="review-chapter-1-5.html"><a href="review-chapter-1-5.html#basic-operation"><i class="fa fa-check"></i><b>6.3</b> Basic Operation<span></span></a></li>
<li class="chapter" data-level="6.4" data-path="review-chapter-1-5.html"><a href="review-chapter-1-5.html#some-basic-plots-in-r"><i class="fa fa-check"></i><b>6.4</b> Some basic plots in R<span></span></a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="data-transformation-with-dplyr.html"><a href="data-transformation-with-dplyr.html"><i class="fa fa-check"></i><b>7</b> Data Transformation with <code>dplyr</code><span></span></a><ul>
<li class="chapter" data-level="7.1" data-path="data-transformation-with-dplyr.html"><a href="data-transformation-with-dplyr.html#introduction-1"><i class="fa fa-check"></i><b>7.1</b> Introduction<span></span></a></li>
<li class="chapter" data-level="7.2" data-path="data-transformation-with-dplyr.html"><a href="data-transformation-with-dplyr.html#arrange"><i class="fa fa-check"></i><b>7.2</b> <code>arrange()</code><span></span></a><ul>
<li class="chapter" data-level="7.2.1" data-path="data-transformation-with-dplyr.html"><a href="data-transformation-with-dplyr.html#exercises-2"><i class="fa fa-check"></i><b>7.2.1</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="data-transformation-with-dplyr.html"><a href="data-transformation-with-dplyr.html#filter"><i class="fa fa-check"></i><b>7.3</b> <code>filter()</code><span></span></a><ul>
<li class="chapter" data-level="7.3.1" data-path="data-transformation-with-dplyr.html"><a href="data-transformation-with-dplyr.html#exercises-3"><i class="fa fa-check"></i><b>7.3.1</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="data-transformation-with-dplyr.html"><a href="data-transformation-with-dplyr.html#select"><i class="fa fa-check"></i><b>7.4</b> <code>select()</code><span></span></a><ul>
<li class="chapter" data-level="7.4.1" data-path="data-transformation-with-dplyr.html"><a href="data-transformation-with-dplyr.html#exercises-4"><i class="fa fa-check"></i><b>7.4.1</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="data-transformation-with-dplyr.html"><a href="data-transformation-with-dplyr.html#mutate"><i class="fa fa-check"></i><b>7.5</b> <code>mutate()</code><span></span></a><ul>
<li class="chapter" data-level="7.5.1" data-path="data-transformation-with-dplyr.html"><a href="data-transformation-with-dplyr.html#exercises-5"><i class="fa fa-check"></i><b>7.5.1</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="data-transformation-with-dplyr.html"><a href="data-transformation-with-dplyr.html#summarize-group_by"><i class="fa fa-check"></i><b>7.6</b> <code>summarize(), group_by()</code><span></span></a></li>
<li class="chapter" data-level="7.7" data-path="data-transformation-with-dplyr.html"><a href="data-transformation-with-dplyr.html#combining-multiple-operations-with-pipe"><i class="fa fa-check"></i><b>7.7</b> Combining Multiple Operations with Pipe <code>%&gt;%</code><span></span></a></li>
<li class="chapter" data-level="7.8" data-path="data-transformation-with-dplyr.html"><a href="data-transformation-with-dplyr.html#summary"><i class="fa fa-check"></i><b>7.8</b> Summary<span></span></a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="data-visualization-with-ggplot2.html"><a href="data-visualization-with-ggplot2.html"><i class="fa fa-check"></i><b>8</b> Data Visualization with ggplot2<span></span></a><ul>
<li class="chapter" data-level="8.1" data-path="data-visualization-with-ggplot2.html"><a href="data-visualization-with-ggplot2.html#bar-charts"><i class="fa fa-check"></i><b>8.1</b> Bar charts<span></span></a></li>
<li class="chapter" data-level="8.2" data-path="data-visualization-with-ggplot2.html"><a href="data-visualization-with-ggplot2.html#line-graph-1"><i class="fa fa-check"></i><b>8.2</b> Line Graph<span></span></a></li>
<li class="chapter" data-level="8.3" data-path="data-visualization-with-ggplot2.html"><a href="data-visualization-with-ggplot2.html#scatter-plots"><i class="fa fa-check"></i><b>8.3</b> Scatter Plots<span></span></a><ul>
<li class="chapter" data-level="8.3.1" data-path="data-visualization-with-ggplot2.html"><a href="data-visualization-with-ggplot2.html#overplotting"><i class="fa fa-check"></i><b>8.3.1</b> Overplotting<span></span></a></li>
<li class="chapter" data-level="8.3.2" data-path="data-visualization-with-ggplot2.html"><a href="data-visualization-with-ggplot2.html#labelling-points-in-a-scatter-plot"><i class="fa fa-check"></i><b>8.3.2</b> Labelling points in a scatter plot<span></span></a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="data-visualization-with-ggplot2.html"><a href="data-visualization-with-ggplot2.html#summarizing-data-distributions"><i class="fa fa-check"></i><b>8.4</b> Summarizing Data Distributions<span></span></a><ul>
<li class="chapter" data-level="8.4.1" data-path="data-visualization-with-ggplot2.html"><a href="data-visualization-with-ggplot2.html#histogram-1"><i class="fa fa-check"></i><b>8.4.1</b> Histogram<span></span></a></li>
<li class="chapter" data-level="8.4.2" data-path="data-visualization-with-ggplot2.html"><a href="data-visualization-with-ggplot2.html#kernel-density-estimate"><i class="fa fa-check"></i><b>8.4.2</b> Kernel Density Estimate<span></span></a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="data-visualization-with-ggplot2.html"><a href="data-visualization-with-ggplot2.html#saving-your-plots"><i class="fa fa-check"></i><b>8.5</b> Saving your plots<span></span></a><ul>
<li class="chapter" data-level="8.5.1" data-path="data-visualization-with-ggplot2.html"><a href="data-visualization-with-ggplot2.html#outputting-to-pdf-vector-files"><i class="fa fa-check"></i><b>8.5.1</b> Outputting to pdf vector files<span></span></a></li>
<li class="chapter" data-level="8.5.2" data-path="data-visualization-with-ggplot2.html"><a href="data-visualization-with-ggplot2.html#outputting-to-bitmap-files"><i class="fa fa-check"></i><b>8.5.2</b> Outputting to bitmap files<span></span></a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="data-visualization-with-ggplot2.html"><a href="data-visualization-with-ggplot2.html#summary-1"><i class="fa fa-check"></i><b>8.6</b> Summary<span></span></a><ul>
<li class="chapter" data-level="8.6.1" data-path="data-visualization-with-ggplot2.html"><a href="data-visualization-with-ggplot2.html#combining-multiple-operations-with-pipe-1"><i class="fa fa-check"></i><b>8.6.1</b> Combining multiple operations with pipe <code>%&gt;%</code><span></span></a></li>
<li class="chapter" data-level="8.6.2" data-path="data-visualization-with-ggplot2.html"><a href="data-visualization-with-ggplot2.html#bar-charts-1"><i class="fa fa-check"></i><b>8.6.2</b> Bar charts<span></span></a></li>
<li class="chapter" data-level="8.6.3" data-path="data-visualization-with-ggplot2.html"><a href="data-visualization-with-ggplot2.html#line-graphs"><i class="fa fa-check"></i><b>8.6.3</b> Line graphs<span></span></a></li>
<li class="chapter" data-level="8.6.4" data-path="data-visualization-with-ggplot2.html"><a href="data-visualization-with-ggplot2.html#scatter-plot-1"><i class="fa fa-check"></i><b>8.6.4</b> Scatter plot<span></span></a></li>
<li class="chapter" data-level="8.6.5" data-path="data-visualization-with-ggplot2.html"><a href="data-visualization-with-ggplot2.html#summarizing-data-distributions-1"><i class="fa fa-check"></i><b>8.6.5</b> Summarizing data distributions<span></span></a></li>
<li class="chapter" data-level="8.6.6" data-path="data-visualization-with-ggplot2.html"><a href="data-visualization-with-ggplot2.html#saving-your-plots-1"><i class="fa fa-check"></i><b>8.6.6</b> Saving your plots<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="statistical-inference-in-r.html"><a href="statistical-inference-in-r.html"><i class="fa fa-check"></i><b>9</b> Statistical Inference in R<span></span></a><ul>
<li class="chapter" data-level="9.1" data-path="statistical-inference-in-r.html"><a href="statistical-inference-in-r.html#maximum-likelihood-estimation"><i class="fa fa-check"></i><b>9.1</b> Maximum Likelihood Estimation<span></span></a><ul>
<li class="chapter" data-level="9.1.1" data-path="statistical-inference-in-r.html"><a href="statistical-inference-in-r.html#exercises-on-mle"><i class="fa fa-check"></i><b>9.1.1</b> Exercises on MLE<span></span></a></li>
<li class="chapter" data-level="9.1.2" data-path="statistical-inference-in-r.html"><a href="statistical-inference-in-r.html#summary-2"><i class="fa fa-check"></i><b>9.1.2</b> Summary<span></span></a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="statistical-inference-in-r.html"><a href="statistical-inference-in-r.html#interval-estimation-and-hypothesis-testing"><i class="fa fa-check"></i><b>9.2</b> Interval Estimation and Hypothesis Testing<span></span></a><ul>
<li class="chapter" data-level="9.2.1" data-path="statistical-inference-in-r.html"><a href="statistical-inference-in-r.html#examples-of-hypothesis-testing"><i class="fa fa-check"></i><b>9.2.1</b> Examples of Hypothesis Testing<span></span></a></li>
<li class="chapter" data-level="9.2.2" data-path="statistical-inference-in-r.html"><a href="statistical-inference-in-r.html#null-hypotheses-alternative-hypotheses-and-p-values"><i class="fa fa-check"></i><b>9.2.2</b> Null Hypotheses, Alternative Hypotheses, and p-values<span></span></a></li>
<li class="chapter" data-level="9.2.3" data-path="statistical-inference-in-r.html"><a href="statistical-inference-in-r.html#type-i-error-and-type-ii-error"><i class="fa fa-check"></i><b>9.2.3</b> Type I error and Type II error<span></span></a></li>
<li class="chapter" data-level="9.2.4" data-path="statistical-inference-in-r.html"><a href="statistical-inference-in-r.html#inference-for-mean-of-one-sample"><i class="fa fa-check"></i><b>9.2.4</b> Inference for Mean of One Sample<span></span></a></li>
<li class="chapter" data-level="9.2.5" data-path="statistical-inference-in-r.html"><a href="statistical-inference-in-r.html#comparing-the-means-of-two-samples"><i class="fa fa-check"></i><b>9.2.5</b> Comparing the means of two samples<span></span></a></li>
<li class="chapter" data-level="9.2.6" data-path="statistical-inference-in-r.html"><a href="statistical-inference-in-r.html#inference-of-a-sample-proportion"><i class="fa fa-check"></i><b>9.2.6</b> Inference of a Sample Proportion<span></span></a></li>
<li class="chapter" data-level="9.2.7" data-path="statistical-inference-in-r.html"><a href="statistical-inference-in-r.html#testing-groups-for-equal-proportions"><i class="fa fa-check"></i><b>9.2.7</b> Testing groups for equal proportions<span></span></a></li>
<li class="chapter" data-level="9.2.8" data-path="statistical-inference-in-r.html"><a href="statistical-inference-in-r.html#testing-if-two-samples-have-the-same-underlying-distribution"><i class="fa fa-check"></i><b>9.2.8</b> Testing if two samples have the same underlying distribution<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="root-finding-and-optimization.html"><a href="root-finding-and-optimization.html"><i class="fa fa-check"></i><b>10</b> Root finding and optimization<span></span></a><ul>
<li class="chapter" data-level="10.1" data-path="root-finding-and-optimization.html"><a href="root-finding-and-optimization.html#root-finding"><i class="fa fa-check"></i><b>10.1</b> Root Finding<span></span></a><ul>
<li class="chapter" data-level="10.1.1" data-path="root-finding-and-optimization.html"><a href="root-finding-and-optimization.html#bisection-method"><i class="fa fa-check"></i><b>10.1.1</b> Bisection Method<span></span></a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="root-finding-and-optimization.html"><a href="root-finding-and-optimization.html#newton-raphson-method"><i class="fa fa-check"></i><b>10.2</b> Newton-Raphson Method<span></span></a></li>
<li class="chapter" data-level="10.3" data-path="root-finding-and-optimization.html"><a href="root-finding-and-optimization.html#minimization-and-maximization"><i class="fa fa-check"></i><b>10.3</b> Minimization and Maximization<span></span></a><ul>
<li class="chapter" data-level="10.3.1" data-path="root-finding-and-optimization.html"><a href="root-finding-and-optimization.html#newton-raphson-method-1"><i class="fa fa-check"></i><b>10.3.1</b> Newton-Raphson Method<span></span></a></li>
<li class="chapter" data-level="10.3.2" data-path="root-finding-and-optimization.html"><a href="root-finding-and-optimization.html#gradient-descent"><i class="fa fa-check"></i><b>10.3.2</b> Gradient Descent<span></span></a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="root-finding-and-optimization.html"><a href="root-finding-and-optimization.html#optim"><i class="fa fa-check"></i><b>10.4</b> <code>optim</code><span></span></a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html"><i class="fa fa-check"></i><b>11</b> k-nearest neighbors<span></span></a><ul>
<li class="chapter" data-level="11.1" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#introduction-2"><i class="fa fa-check"></i><b>11.1</b> Introduction<span></span></a></li>
<li class="chapter" data-level="11.2" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#feature-scaling"><i class="fa fa-check"></i><b>11.2</b> Feature Scaling<span></span></a></li>
<li class="chapter" data-level="11.3" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#example-classifying-breast-cancers"><i class="fa fa-check"></i><b>11.3</b> Example: Classifying Breast Cancers<span></span></a><ul>
<li class="chapter" data-level="11.3.1" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#evaluating-model-performance"><i class="fa fa-check"></i><b>11.3.1</b> Evaluating Model Performance<span></span></a></li>
<li class="chapter" data-level="11.3.2" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#using-z-score-standardization"><i class="fa fa-check"></i><b>11.3.2</b> Using <span class="math inline">\(z\)</span>-score standardization<span></span></a></li>
<li class="chapter" data-level="11.3.3" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#testing-alternative-values-of-k"><i class="fa fa-check"></i><b>11.3.3</b> Testing alternative values of <span class="math inline">\(k\)</span><span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="linear-regression-models.html"><a href="linear-regression-models.html"><i class="fa fa-check"></i><b>12</b> Linear Regression Models<span></span></a><ul>
<li class="chapter" data-level="12.1" data-path="linear-regression-models.html"><a href="linear-regression-models.html#simple-linear-regression"><i class="fa fa-check"></i><b>12.1</b> Simple Linear Regression<span></span></a></li>
<li class="chapter" data-level="12.2" data-path="linear-regression-models.html"><a href="linear-regression-models.html#smoothed-conditional-means"><i class="fa fa-check"></i><b>12.2</b> Smoothed Conditional Means<span></span></a></li>
<li class="chapter" data-level="12.3" data-path="linear-regression-models.html"><a href="linear-regression-models.html#multiple-linear-regression"><i class="fa fa-check"></i><b>12.3</b> Multiple Linear Regression<span></span></a></li>
<li class="chapter" data-level="12.4" data-path="linear-regression-models.html"><a href="linear-regression-models.html#example-diamonds"><i class="fa fa-check"></i><b>12.4</b> Example: <code>diamonds</code><span></span></a></li>
<li class="chapter" data-level="12.5" data-path="linear-regression-models.html"><a href="linear-regression-models.html#categorical-predictors"><i class="fa fa-check"></i><b>12.5</b> Categorical Predictors<span></span></a></li>
<li class="chapter" data-level="12.6" data-path="linear-regression-models.html"><a href="linear-regression-models.html#compare-models-using-anova"><i class="fa fa-check"></i><b>12.6</b> Compare models using ANOVA<span></span></a></li>
<li class="chapter" data-level="12.7" data-path="linear-regression-models.html"><a href="linear-regression-models.html#prediction"><i class="fa fa-check"></i><b>12.7</b> Prediction<span></span></a></li>
<li class="chapter" data-level="12.8" data-path="linear-regression-models.html"><a href="linear-regression-models.html#interaction-terms"><i class="fa fa-check"></i><b>12.8</b> Interaction Terms<span></span></a></li>
<li class="chapter" data-level="12.9" data-path="linear-regression-models.html"><a href="linear-regression-models.html#variable-transformation"><i class="fa fa-check"></i><b>12.9</b> Variable Transformation<span></span></a></li>
<li class="chapter" data-level="12.10" data-path="linear-regression-models.html"><a href="linear-regression-models.html#polynomial-regression"><i class="fa fa-check"></i><b>12.10</b> Polynomial Regression<span></span></a></li>
<li class="chapter" data-level="12.11" data-path="linear-regression-models.html"><a href="linear-regression-models.html#stepwise-regression"><i class="fa fa-check"></i><b>12.11</b> Stepwise regression<span></span></a></li>
<li class="chapter" data-level="12.12" data-path="linear-regression-models.html"><a href="linear-regression-models.html#best-subset"><i class="fa fa-check"></i><b>12.12</b> Best subset<span></span></a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="logistic-regression-model.html"><a href="logistic-regression-model.html"><i class="fa fa-check"></i><b>13</b> Logistic Regression Model<span></span></a></li>
<li class="chapter" data-level="14" data-path="k-means-clustering.html"><a href="k-means-clustering.html"><i class="fa fa-check"></i><b>14</b> k-means Clustering<span></span></a><ul>
<li class="chapter" data-level="14.1" data-path="k-means-clustering.html"><a href="k-means-clustering.html#introduction-3"><i class="fa fa-check"></i><b>14.1</b> Introduction<span></span></a></li>
<li class="chapter" data-level="14.2" data-path="k-means-clustering.html"><a href="k-means-clustering.html#applications"><i class="fa fa-check"></i><b>14.2</b> Applications<span></span></a><ul>
<li class="chapter" data-level="14.2.1" data-path="k-means-clustering.html"><a href="k-means-clustering.html#cluster-analysis"><i class="fa fa-check"></i><b>14.2.1</b> Cluster Analysis<span></span></a></li>
<li class="chapter" data-level="14.2.2" data-path="k-means-clustering.html"><a href="k-means-clustering.html#image-segementation-and-image-compression"><i class="fa fa-check"></i><b>14.2.2</b> Image Segementation and Image Compression<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html"><i class="fa fa-check"></i><b>15</b> Hierarchical Clustering<span></span></a><ul>
<li class="chapter" data-level="15.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#dissimilarity-measure-and-linkage"><i class="fa fa-check"></i><b>15.1</b> Dissimilarity measure and Linkage<span></span></a></li>
<li class="chapter" data-level="15.2" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#alogrithm"><i class="fa fa-check"></i><b>15.2</b> Alogrithm<span></span></a></li>
<li class="chapter" data-level="15.3" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#applications-1"><i class="fa fa-check"></i><b>15.3</b> Applications<span></span></a><ul>
<li class="chapter" data-level="15.3.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#nci60-data"><i class="fa fa-check"></i><b>15.3.1</b> NCI60 Data<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="resampling-methods.html"><a href="resampling-methods.html"><i class="fa fa-check"></i><b>16</b> Resampling Methods<span></span></a><ul>
<li class="chapter" data-level="16.1" data-path="resampling-methods.html"><a href="resampling-methods.html#cross-validation"><i class="fa fa-check"></i><b>16.1</b> Cross-validation<span></span></a><ul>
<li class="chapter" data-level="16.1.1" data-path="resampling-methods.html"><a href="resampling-methods.html#cv-in-glm"><i class="fa fa-check"></i><b>16.1.1</b> CV in GLM<span></span></a></li>
<li class="chapter" data-level="16.1.2" data-path="resampling-methods.html"><a href="resampling-methods.html#general-implementation"><i class="fa fa-check"></i><b>16.1.2</b> General Implementation<span></span></a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="resampling-methods.html"><a href="resampling-methods.html#bootstrap"><i class="fa fa-check"></i><b>16.2</b> Bootstrap<span></span></a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="regularization.html"><a href="regularization.html"><i class="fa fa-check"></i><b>17</b> Regularization<span></span></a><ul>
<li class="chapter" data-level="17.1" data-path="regularization.html"><a href="regularization.html#ridge-regression"><i class="fa fa-check"></i><b>17.1</b> Ridge Regression<span></span></a></li>
<li class="chapter" data-level="17.2" data-path="regularization.html"><a href="regularization.html#lasso"><i class="fa fa-check"></i><b>17.2</b> LASSO<span></span></a></li>
<li class="chapter" data-level="17.3" data-path="regularization.html"><a href="regularization.html#selecting-the-tuning-parameter"><i class="fa fa-check"></i><b>17.3</b> Selecting the tuning parameter<span></span></a></li>
<li class="chapter" data-level="17.4" data-path="regularization.html"><a href="regularization.html#glmnet"><i class="fa fa-check"></i><b>17.4</b> <code>glmnet</code><span></span></a><ul>
<li class="chapter" data-level="17.4.1" data-path="regularization.html"><a href="regularization.html#ridge-regression-1"><i class="fa fa-check"></i><b>17.4.1</b> Ridge Regression<span></span></a></li>
<li class="chapter" data-level="17.4.2" data-path="regularization.html"><a href="regularization.html#lasso-1"><i class="fa fa-check"></i><b>17.4.2</b> LASSO<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>18</b> Decision Trees<span></span></a><ul>
<li class="chapter" data-level="18.1" data-path="decision-trees.html"><a href="decision-trees.html#introduction-to-classification-tree"><i class="fa fa-check"></i><b>18.1</b> Introduction to Classification Tree<span></span></a></li>
<li class="chapter" data-level="18.2" data-path="decision-trees.html"><a href="decision-trees.html#introduction-to-regression-tree"><i class="fa fa-check"></i><b>18.2</b> Introduction to regression tree<span></span></a></li>
<li class="chapter" data-level="18.3" data-path="decision-trees.html"><a href="decision-trees.html#mathematical-formulation"><i class="fa fa-check"></i><b>18.3</b> Mathematical Formulation<span></span></a></li>
<li class="chapter" data-level="18.4" data-path="decision-trees.html"><a href="decision-trees.html#examples"><i class="fa fa-check"></i><b>18.4</b> Examples<span></span></a><ul>
<li class="chapter" data-level="18.4.1" data-path="decision-trees.html"><a href="decision-trees.html#classification-tree"><i class="fa fa-check"></i><b>18.4.1</b> Classification Tree<span></span></a></li>
<li class="chapter" data-level="18.4.2" data-path="decision-trees.html"><a href="decision-trees.html#regression-tree"><i class="fa fa-check"></i><b>18.4.2</b> Regression Tree<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="ensemble-methods.html"><a href="ensemble-methods.html"><i class="fa fa-check"></i><b>19</b> Ensemble Methods<span></span></a><ul>
<li class="chapter" data-level="19.1" data-path="ensemble-methods.html"><a href="ensemble-methods.html#bagging"><i class="fa fa-check"></i><b>19.1</b> Bagging<span></span></a></li>
<li class="chapter" data-level="19.2" data-path="ensemble-methods.html"><a href="ensemble-methods.html#random-forest"><i class="fa fa-check"></i><b>19.2</b> Random Forest<span></span></a></li>
<li class="chapter" data-level="19.3" data-path="ensemble-methods.html"><a href="ensemble-methods.html#example"><i class="fa fa-check"></i><b>19.3</b> Example<span></span></a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="deep-learning.html"><a href="deep-learning.html"><i class="fa fa-check"></i><b>20</b> Deep Learning<span></span></a><ul>
<li class="chapter" data-level="20.1" data-path="deep-learning.html"><a href="deep-learning.html#introduction-4"><i class="fa fa-check"></i><b>20.1</b> Introduction<span></span></a></li>
<li class="chapter" data-level="20.2" data-path="deep-learning.html"><a href="deep-learning.html#single-layer-neural-netowrks"><i class="fa fa-check"></i><b>20.2</b> Single Layer Neural Netowrks<span></span></a></li>
<li class="chapter" data-level="20.3" data-path="deep-learning.html"><a href="deep-learning.html#multilayer-neurla-networks"><i class="fa fa-check"></i><b>20.3</b> Multilayer Neurla Networks<span></span></a></li>
<li class="chapter" data-level="20.4" data-path="deep-learning.html"><a href="deep-learning.html#keras"><i class="fa fa-check"></i><b>20.4</b> Keras<span></span></a></li>
<li class="chapter" data-level="20.5" data-path="deep-learning.html"><a href="deep-learning.html#two-class-classification-binary-classification"><i class="fa fa-check"></i><b>20.5</b> Two-class classification (binary classification)<span></span></a></li>
<li class="chapter" data-level="20.6" data-path="deep-learning.html"><a href="deep-learning.html#binary-classification"><i class="fa fa-check"></i><b>20.6</b> Binary Classification<span></span></a></li>
<li class="chapter" data-level="20.7" data-path="deep-learning.html"><a href="deep-learning.html#multiclass-classification"><i class="fa fa-check"></i><b>20.7</b> Multiclass Classification<span></span></a></li>
<li class="chapter" data-level="20.8" data-path="deep-learning.html"><a href="deep-learning.html#regression"><i class="fa fa-check"></i><b>20.8</b> Regression<span></span></a></li>
<li class="chapter" data-level="20.9" data-path="deep-learning.html"><a href="deep-learning.html#appendix"><i class="fa fa-check"></i><b>20.9</b> Appendix<span></span></a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">STAT 362 R for Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="deep-learning" class="section level1 hasAnchor">
<h1><span class="header-section-number">Chapter 20</span> Deep Learning<a href="deep-learning.html#deep-learning" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Reference: Deep Learning with R by Francois Chollet with J.J. Allaire</p>
<p><a href="https://tensorflow.rstudio.com/tutorials/beginners/" class="uri">https://tensorflow.rstudio.com/tutorials/beginners/</a></p>
<p>Ch10 in An introduction to Statistical Leraning with applications in R by James, Witten, Hastie and Tibshirani.</p>
<div id="introduction-4" class="section level2 hasAnchor">
<h2><span class="header-section-number">20.1</span> Introduction<a href="deep-learning.html#introduction-4" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the past few years, artificial intelligence (AI), machine learning, deep learning have been subjects of intense media hype.</p>
<p>One may define AI as the study to automate intellectual tasks normally performed by humans. AI encompasses machine learning but also includes other approaches that don’t involve any learning. For example, early chess programs only involved hardcoded rules crafted by programmers. For a fairly long time, many experts believed that human-level AI could be achieved by having programmers handcraft a sufficiently large set of explicit rules for manipulating knowledge. This approach is known as symbolic AI.</p>
<p>It turns out it is intractable to figure out explicit rules for solving more complex problems, such as image classification, speech recognition, and language translation. A new appraoch is to use machine learning.</p>
<p>You have already studied various machine learning methods and how to apply them with R: <span class="math inline">\(k\)</span>-NN, linear regression, logistic regression, <span class="math inline">\(k\)</span>-means clustering, hierarchical clustering, ridge regression, LASSO, decision trees, random forest. These approaches are also examples of shallow learning.</p>
<p>What is deep learning?</p>
<ul>
<li><p>Deep learning is a subset of machine learning</p></li>
<li><p>The deep in deep learning refers to the idea of successive layers of representations.</p></li>
<li><p>These layered representations are learned via neural networks.</p></li>
<li><p>Deep learning took off after 2012. Three factors drive the advances in machine learning</p>
<ul>
<li>Hardware (CPU, GPU, TPU)</li>
<li>Datasets and benchmarks (the rise of internet allows people to collect many data, competitions (e.g. Kaggle) allow people to have benchmarks that researchers compete to beat)</li>
<li>Algorithmic advances</li>
</ul></li>
<li><p>The cornerstone of deep learning is neural network.</p></li>
</ul>
</div>
<div id="single-layer-neural-netowrks" class="section level2 hasAnchor">
<h2><span class="header-section-number">20.2</span> Single Layer Neural Netowrks<a href="deep-learning.html#single-layer-neural-netowrks" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A neural network takes an input vector of <span class="math inline">\(p\)</span> variables <span class="math inline">\(X = (X_1,\ldots,X_p)\)</span> and builds a nonlinear function <span class="math inline">\(f(x)\)</span> to predict the repsonse <span class="math inline">\(Y\)</span>.</p>
<ul>
<li>Input layer: consists of the <span class="math inline">\(p\)</span> variables</li>
<li>Hidden layer: consists of <span class="math inline">\(K\)</span> hidden units (the picture shows <span class="math inline">\(5\)</span> but we can have many more)</li>
</ul>
<p>Activations <span class="math inline">\(A_k\)</span>, <span class="math inline">\(k=1,\ldots,K\)</span> are computed as functions of the input features
<span class="math display">\[\begin{equation*}
A_k = h_k(X) = g(w_{k0} + \sum^p_{j=1} w_{kj}X_j),
\end{equation*}\]</span>
where <span class="math inline">\(g\)</span> is a nonlinear activation function that is specified in advance. For example, it is common to use ReLU (rectified linear unit), which takes the form
<span class="math display">\[\begin{equation*}
g(z) = z I(z \geq 0).
\end{equation*}\]</span>
With nonlinear activation functions, it is possible for the model to capture complex nonlinearities and interaction effects (e.g. <span class="math inline">\(X_1 X_2\)</span>).</p>
<p>We can think of each <span class="math inline">\(A_k\)</span> as a different transformation <span class="math inline">\(h_k(X)\)</span> of the original features.</p>
<p>For regression problem, the output is
<span class="math display">\[\begin{equation*}
f(X) = \beta_0 + \sum^K_{k=1} \beta_k A_k.
\end{equation*}\]</span></p>
<p>Parameters in the model: <span class="math inline">\(\beta_0,\ldots,\beta_K, w_{10},\ldots,w_{Kp}\)</span>.</p>
<p>To estimate these parameters, the squared-error loss is typically used. That is, we wish to find parameters to minimize
<span class="math display">\[\begin{equation*}
\sum^n_{i=1} (y_i - f(x_i))^2.
\end{equation*}\]</span></p>
<p>The name neural network originally derived from thinking of the model as analogous to neurons in the brain. But there is no need to think in that way.</p>
</div>
<div id="multilayer-neurla-networks" class="section level2 hasAnchor">
<h2><span class="header-section-number">20.3</span> Multilayer Neurla Networks<a href="deep-learning.html#multilayer-neurla-networks" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li><p>Modern neural networks typically have more than one hidden layer, and many units per layer.</p></li>
<li><p>In general, you can have more than one output variable. In particular, if you have a classification problem at hand with <span class="math inline">\(M\)</span> classes. You will need <span class="math inline">\(M\)</span> output variables.</p></li>
</ul>
<p>An example of a neural network with two hidden layers:</p>
<p>The activations in the first hidden layer:
<span class="math display">\[\begin{equation*}
A^{(1)}_k = g(w^{(1)}_{k0} + \sum^p_{j=1} w^{(1)}_{kj} X_j)
\end{equation*}\]</span>
for <span class="math inline">\(k=1,\ldots,K_1\)</span>.</p>
<p>The activations in the second hidden layer treats the activations <span class="math inline">\(A^{(1)}_k\)</span> of the first hidden layer as inputs and computes new activations:</p>
<p><span class="math display">\[\begin{equation*}
A^{(2)}_k = g(w^{(2)}_{k0} + \sum^{K_1}_{k=1} w^{(2)}_{kj} A_k^{(1)})
\end{equation*}\]</span></p>
<p>The name neural network originally derived from thinking of the model as analogous to neurons in the brain. But there is no need to think in that way.</p>
</div>
<div id="keras" class="section level2 hasAnchor">
<h2><span class="header-section-number">20.4</span> Keras<a href="deep-learning.html#keras" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Keras is a deep-learning framework that provides a convenient way to define and train deep-learning models.</p>
<ul>
<li>allow the code to run on CPU or GPU</li>
</ul>
<p>almost every recent deep-learning competition has been won using Keras models</p>
<p>One of the backend implementations in Keras is TensorFlow, which is one of the primary platforms for deep learning today.</p>
<p>Installation:</p>
<p>For serious deep learning users, need to train deep learning using GPUs.</p>
</div>
<div id="two-class-classification-binary-classification" class="section level2 hasAnchor">
<h2><span class="header-section-number">20.5</span> Two-class classification (binary classification)<a href="deep-learning.html#two-class-classification-binary-classification" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The IMDB dataset</p>
<p>We’ll be working with “IMDB dataset”, a set of 50,000 highly-polarized reviews from the Internet Movie Database. They are split into 25,000 reviews for training and 25,000 reviews for testing, each set consisting in 50% negative and 50% positive reviews.</p>
<p>the IMDB dataset comes packaged with Keras. It has already been preprocessed: the reviews (sequences of words) have been turned into sequences of integers, where each integer stands for a specific word in a dictionary.</p>
<p>The following code will load the dataset (when you run it for the first time, about 80MB of data will be downloaded to your machine):</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="deep-learning.html#cb1-1"></a><span class="kw">library</span>(keras)</span>
<span id="cb1-2"><a href="deep-learning.html#cb1-2"></a></span>
<span id="cb1-3"><a href="deep-learning.html#cb1-3"></a>imdb &lt;-<span class="st"> </span><span class="kw">dataset_imdb</span>(<span class="dt">num_words =</span> <span class="dv">10000</span>)</span>
<span id="cb1-4"><a href="deep-learning.html#cb1-4"></a><span class="kw">c</span>(<span class="kw">c</span>(train_data, train_labels), <span class="kw">c</span>(test_data, test_labels)) <span class="op">%&lt;-%</span><span class="st"> </span>imdb</span></code></pre></div>
<p>The argument <code>num_words = 10000</code> means that we will only keep the top 10,000 most frequently occurring words in the training data. Rare words will be discarded. This allows us to work with vector data of manageable size.</p>
<p>The variables <code>train_data</code> and <code>test_data</code> are lists of reviews, each review being a list of word indices (encoding a sequence of words). <code>train_labels</code> and <code>test_labels</code> are lists of 0s and 1s, where 0 stands for “negative” and 1 stands for “positive”:</p>
<p>Layers</p>
<p>Input data</p>
<p>Loss function</p>
</div>
<div id="binary-classification" class="section level2 hasAnchor">
<h2><span class="header-section-number">20.6</span> Binary Classification<a href="deep-learning.html#binary-classification" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The goal is to classify movie reviews as positive or negative.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="deep-learning.html#cb2-1"></a><span class="kw">library</span>(keras)</span>
<span id="cb2-2"><a href="deep-learning.html#cb2-2"></a></span>
<span id="cb2-3"><a href="deep-learning.html#cb2-3"></a>imdb &lt;-<span class="st"> </span><span class="kw">dataset_imdb</span>(<span class="dt">num_words =</span> <span class="dv">10000</span>)</span>
<span id="cb2-4"><a href="deep-learning.html#cb2-4"></a></span>
<span id="cb2-5"><a href="deep-learning.html#cb2-5"></a>train_data &lt;-<span class="st"> </span>imdb<span class="op">$</span>train<span class="op">$</span>x</span>
<span id="cb2-6"><a href="deep-learning.html#cb2-6"></a>train_labels &lt;-<span class="st"> </span>imdb<span class="op">$</span>train<span class="op">$</span>y</span>
<span id="cb2-7"><a href="deep-learning.html#cb2-7"></a></span>
<span id="cb2-8"><a href="deep-learning.html#cb2-8"></a>test_data &lt;-<span class="st"> </span>imdb<span class="op">$</span>test<span class="op">$</span>x</span>
<span id="cb2-9"><a href="deep-learning.html#cb2-9"></a>test_labels &lt;-<span class="st"> </span>imdb<span class="op">$</span>test<span class="op">$</span>y</span></code></pre></div>
<p>The argument <code>num_words = 10000</code> means that we will only keep the top <span class="math inline">\(10,000\)</span> most frequently occurring words in the training data. Rare words will be discarded. This allows us to work with vector data of manageable size.</p>
<p>The variables <code>train_data</code> and <code>test_data</code> are lists of reviews, each review being a vector of word indices (encoding a sequence of words).</p>
<p>For example,</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="deep-learning.html#cb3-1"></a><span class="kw">str</span>(train_data[[<span class="dv">1</span>]]) </span>
<span id="cb3-2"><a href="deep-learning.html#cb3-2"></a><span class="co">##  int [1:218] 1 14 22 16 43 530 973 1622 1385 65 ...</span></span></code></pre></div>
<p>The idea is to use an integer to represent a word. For example, <code>14</code> corresponds to <code>this</code>, <code>22</code> corresponds to <code>film</code>, <code>16</code> corresponds to <code>was</code>, etc.</p>
<p><code>train_labels</code> and <code>test_labels</code> are vectors of <span class="math inline">\(0\)</span>s and <span class="math inline">\(1\)</span>s, where <span class="math inline">\(0\)</span> stands for “negative” and <span class="math inline">\(1\)</span> stands for “positive”:</p>
<p><strong>Encoding the data</strong></p>
<p>As a basic illustration, we will not make use of the order of the words (the order of the words in a text can be meaningful). Each review now is a vector of integers. Since we do not make use of the order of the words, we only need to record which words appear for each review. We assign each appeared word by <span class="math inline">\(1\)</span>.</p>
<p>For example, suppose you have two reviews and there are only <span class="math inline">\(5\)</span> possible words. Suppose that the first review is <code>c(1, 5, 3)</code> and the second review is <code>c(2, 5, 4)</code>. Then we want to encode the two reviews into a binary matrix</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="deep-learning.html#cb4-1"></a><span class="co"># the data </span></span>
<span id="cb4-2"><a href="deep-learning.html#cb4-2"></a>reviews &lt;-<span class="st"> </span><span class="kw">list</span>()</span>
<span id="cb4-3"><a href="deep-learning.html#cb4-3"></a><span class="co"># e.g. 1 = not, 2 = is, 3 = good, 4 = bad, 5 = very </span></span>
<span id="cb4-4"><a href="deep-learning.html#cb4-4"></a>reviews[[<span class="dv">1</span>]] &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">3</span>)</span>
<span id="cb4-5"><a href="deep-learning.html#cb4-5"></a>reviews[[<span class="dv">2</span>]] &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">4</span>)</span>
<span id="cb4-6"><a href="deep-learning.html#cb4-6"></a><span class="kw">vectorize_sequences</span>(reviews, <span class="dt">dimension =</span> <span class="dv">5</span>)</span>
<span id="cb4-7"><a href="deep-learning.html#cb4-7"></a><span class="co">##      [,1] [,2] [,3] [,4] [,5]</span></span>
<span id="cb4-8"><a href="deep-learning.html#cb4-8"></a><span class="co">## [1,]    1    0    1    0    1</span></span>
<span id="cb4-9"><a href="deep-learning.html#cb4-9"></a><span class="co">## [2,]    0    1    0    1    1</span></span></code></pre></div>
<p>The function <code>vecctorize_sequences</code> can be written as:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="deep-learning.html#cb5-1"></a>vectorize_sequences &lt;-<span class="st"> </span><span class="cf">function</span>(sequences, <span class="dt">dimension =</span> <span class="dv">10000</span>) {</span>
<span id="cb5-2"><a href="deep-learning.html#cb5-2"></a>  results &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>, <span class="dt">nrow =</span> <span class="kw">length</span>(sequences), <span class="dt">ncol =</span> dimension)</span>
<span id="cb5-3"><a href="deep-learning.html#cb5-3"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(sequences)) {</span>
<span id="cb5-4"><a href="deep-learning.html#cb5-4"></a>    results[i, sequences[[i]]] &lt;-<span class="st"> </span><span class="dv">1</span></span>
<span id="cb5-5"><a href="deep-learning.html#cb5-5"></a>  }</span>
<span id="cb5-6"><a href="deep-learning.html#cb5-6"></a>  <span class="kw">return</span>(results)</span>
<span id="cb5-7"><a href="deep-learning.html#cb5-7"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="deep-learning.html#cb6-1"></a><span class="co"># Our vectorized training data</span></span>
<span id="cb6-2"><a href="deep-learning.html#cb6-2"></a>x_train &lt;-<span class="st"> </span><span class="kw">vectorize_sequences</span>(train_data)</span>
<span id="cb6-3"><a href="deep-learning.html#cb6-3"></a><span class="co"># Our vectorized test data</span></span>
<span id="cb6-4"><a href="deep-learning.html#cb6-4"></a>x_test &lt;-<span class="st"> </span><span class="kw">vectorize_sequences</span>(test_data)</span>
<span id="cb6-5"><a href="deep-learning.html#cb6-5"></a></span>
<span id="cb6-6"><a href="deep-learning.html#cb6-6"></a>y_train &lt;-<span class="st"> </span>train_labels</span>
<span id="cb6-7"><a href="deep-learning.html#cb6-7"></a>y_test &lt;-<span class="st"> </span>test_labels</span>
<span id="cb6-8"><a href="deep-learning.html#cb6-8"></a></span>
<span id="cb6-9"><a href="deep-learning.html#cb6-9"></a>y_train &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(train_labels)</span>
<span id="cb6-10"><a href="deep-learning.html#cb6-10"></a>y_test &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(test_labels)</span></code></pre></div>
<p>Define your model:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="deep-learning.html#cb7-1"></a>model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb7-2"><a href="deep-learning.html#cb7-2"></a><span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">16</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="dt">input_shape =</span> <span class="kw">c</span>(<span class="dv">10000</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb7-3"><a href="deep-learning.html#cb7-3"></a><span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">16</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb7-4"><a href="deep-learning.html#cb7-4"></a><span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">1</span>, <span class="dt">activation =</span> <span class="st">&quot;sigmoid&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="deep-learning.html#cb8-1"></a>model</span>
<span id="cb8-2"><a href="deep-learning.html#cb8-2"></a><span class="co">## Model: &quot;sequential&quot;</span></span>
<span id="cb8-3"><a href="deep-learning.html#cb8-3"></a><span class="co">## ________________________________________________________________________________</span></span>
<span id="cb8-4"><a href="deep-learning.html#cb8-4"></a><span class="co">##  Layer (type)                       Output Shape                    Param #     </span></span>
<span id="cb8-5"><a href="deep-learning.html#cb8-5"></a><span class="co">## ================================================================================</span></span>
<span id="cb8-6"><a href="deep-learning.html#cb8-6"></a><span class="co">##  dense_2 (Dense)                    (None, 16)                      160016      </span></span>
<span id="cb8-7"><a href="deep-learning.html#cb8-7"></a><span class="co">##                                                                                 </span></span>
<span id="cb8-8"><a href="deep-learning.html#cb8-8"></a><span class="co">##  dense_1 (Dense)                    (None, 16)                      272         </span></span>
<span id="cb8-9"><a href="deep-learning.html#cb8-9"></a><span class="co">##                                                                                 </span></span>
<span id="cb8-10"><a href="deep-learning.html#cb8-10"></a><span class="co">##  dense (Dense)                      (None, 1)                       17          </span></span>
<span id="cb8-11"><a href="deep-learning.html#cb8-11"></a><span class="co">##                                                                                 </span></span>
<span id="cb8-12"><a href="deep-learning.html#cb8-12"></a><span class="co">## ================================================================================</span></span>
<span id="cb8-13"><a href="deep-learning.html#cb8-13"></a><span class="co">## Total params: 160,305</span></span>
<span id="cb8-14"><a href="deep-learning.html#cb8-14"></a><span class="co">## Trainable params: 160,305</span></span>
<span id="cb8-15"><a href="deep-learning.html#cb8-15"></a><span class="co">## Non-trainable params: 0</span></span>
<span id="cb8-16"><a href="deep-learning.html#cb8-16"></a><span class="co">## ________________________________________________________________________________</span></span></code></pre></div>
<p>There are <span class="math inline">\(160,305\)</span> parameters in the model!</p>
<p>Compile the model.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="deep-learning.html#cb9-1"></a>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">compile</span>(</span>
<span id="cb9-2"><a href="deep-learning.html#cb9-2"></a>  <span class="dt">optimizer =</span> <span class="st">&quot;rmsprop&quot;</span>,</span>
<span id="cb9-3"><a href="deep-learning.html#cb9-3"></a>  <span class="dt">loss =</span> <span class="st">&quot;binary_crossentropy&quot;</span>,</span>
<span id="cb9-4"><a href="deep-learning.html#cb9-4"></a>  <span class="dt">metrics =</span> <span class="kw">c</span>(<span class="st">&quot;accuracy&quot;</span>)</span>
<span id="cb9-5"><a href="deep-learning.html#cb9-5"></a>)</span></code></pre></div>
<p>Setting aside a validation set</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="deep-learning.html#cb10-1"></a><span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb10-2"><a href="deep-learning.html#cb10-2"></a>index &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">nrow</span>(x_train), <span class="dv">10000</span>)</span>
<span id="cb10-3"><a href="deep-learning.html#cb10-3"></a></span>
<span id="cb10-4"><a href="deep-learning.html#cb10-4"></a>x_val &lt;-<span class="st"> </span>x_train[index,]</span>
<span id="cb10-5"><a href="deep-learning.html#cb10-5"></a>partial_x_train &lt;-<span class="st"> </span>x_train[<span class="op">-</span>index,]</span>
<span id="cb10-6"><a href="deep-learning.html#cb10-6"></a></span>
<span id="cb10-7"><a href="deep-learning.html#cb10-7"></a>y_val &lt;-<span class="st"> </span>y_train[index]</span>
<span id="cb10-8"><a href="deep-learning.html#cb10-8"></a>partial_y_train &lt;-<span class="st"> </span>y_train[<span class="op">-</span>index]</span></code></pre></div>
<p>Train the model</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="deep-learning.html#cb11-1"></a>history &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit</span>(</span>
<span id="cb11-2"><a href="deep-learning.html#cb11-2"></a>  partial_x_train,</span>
<span id="cb11-3"><a href="deep-learning.html#cb11-3"></a>  partial_y_train,</span>
<span id="cb11-4"><a href="deep-learning.html#cb11-4"></a>  <span class="dt">epochs =</span> <span class="dv">20</span>,</span>
<span id="cb11-5"><a href="deep-learning.html#cb11-5"></a>  <span class="dt">batch_size =</span> <span class="dv">512</span>,</span>
<span id="cb11-6"><a href="deep-learning.html#cb11-6"></a>  <span class="dt">validation_data =</span> <span class="kw">list</span>(x_val, y_val)</span>
<span id="cb11-7"><a href="deep-learning.html#cb11-7"></a>)</span></code></pre></div>
<p>Epoch: 1 epoch =</p>
<div class="figure">
<img src="https://s3.amazonaws.com/book.keras.io/img/ch3/3_layer_network.png" alt="" />
<p class="caption">3-layer network</p>
</div>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="deep-learning.html#cb12-1"></a><span class="kw">str</span>(history)</span>
<span id="cb12-2"><a href="deep-learning.html#cb12-2"></a><span class="co">## List of 2</span></span>
<span id="cb12-3"><a href="deep-learning.html#cb12-3"></a><span class="co">##  $ params :List of 3</span></span>
<span id="cb12-4"><a href="deep-learning.html#cb12-4"></a><span class="co">##   ..$ verbose: int 1</span></span>
<span id="cb12-5"><a href="deep-learning.html#cb12-5"></a><span class="co">##   ..$ epochs : int 20</span></span>
<span id="cb12-6"><a href="deep-learning.html#cb12-6"></a><span class="co">##   ..$ steps  : int 30</span></span>
<span id="cb12-7"><a href="deep-learning.html#cb12-7"></a><span class="co">##  $ metrics:List of 4</span></span>
<span id="cb12-8"><a href="deep-learning.html#cb12-8"></a><span class="co">##   ..$ loss        : num [1:20] 0.538 0.326 0.238 0.185 0.151 ...</span></span>
<span id="cb12-9"><a href="deep-learning.html#cb12-9"></a><span class="co">##   ..$ accuracy    : num [1:20] 0.766 0.898 0.926 0.941 0.953 ...</span></span>
<span id="cb12-10"><a href="deep-learning.html#cb12-10"></a><span class="co">##   ..$ val_loss    : num [1:20] 0.404 0.335 0.28 0.276 0.302 ...</span></span>
<span id="cb12-11"><a href="deep-learning.html#cb12-11"></a><span class="co">##   ..$ val_accuracy: num [1:20] 0.871 0.871 0.891 0.889 0.88 ...</span></span>
<span id="cb12-12"><a href="deep-learning.html#cb12-12"></a><span class="co">##  - attr(*, &quot;class&quot;)= chr &quot;keras_training_history&quot;</span></span>
<span id="cb12-13"><a href="deep-learning.html#cb12-13"></a><span class="kw">plot</span>(history)</span></code></pre></div>
<p><img src="Book_files/figure-html/unnamed-chunk-14-1.png" width="75%" style="display: block; margin: auto;" /></p>
<p>Since the validation error starts to increase at <span class="math inline">\(5\)</span> epoch, we shall only train our model with <span class="math inline">\(4\)</span> epoch.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="deep-learning.html#cb13-1"></a>model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb13-2"><a href="deep-learning.html#cb13-2"></a><span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">16</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="dt">input_shape =</span> <span class="kw">c</span>(<span class="dv">10000</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb13-3"><a href="deep-learning.html#cb13-3"></a><span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">16</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb13-4"><a href="deep-learning.html#cb13-4"></a><span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">1</span>, <span class="dt">activation =</span> <span class="st">&quot;sigmoid&quot;</span>)</span>
<span id="cb13-5"><a href="deep-learning.html#cb13-5"></a></span>
<span id="cb13-6"><a href="deep-learning.html#cb13-6"></a>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">compile</span>(</span>
<span id="cb13-7"><a href="deep-learning.html#cb13-7"></a>  <span class="dt">optimizer =</span> <span class="st">&quot;rmsprop&quot;</span>,</span>
<span id="cb13-8"><a href="deep-learning.html#cb13-8"></a>  <span class="dt">loss =</span> <span class="st">&quot;binary_crossentropy&quot;</span>,</span>
<span id="cb13-9"><a href="deep-learning.html#cb13-9"></a>  <span class="dt">metrics =</span> <span class="kw">c</span>(<span class="st">&quot;accuracy&quot;</span>)</span>
<span id="cb13-10"><a href="deep-learning.html#cb13-10"></a>)</span>
<span id="cb13-11"><a href="deep-learning.html#cb13-11"></a></span>
<span id="cb13-12"><a href="deep-learning.html#cb13-12"></a>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit</span>(x_train, y_train, <span class="dt">epochs =</span> <span class="dv">4</span>, <span class="dt">batch_size =</span> <span class="dv">512</span>)</span></code></pre></div>
<p><strong>Prediction Accuracy in test data</strong></p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="deep-learning.html#cb14-1"></a>(results &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">evaluate</span>(x_test, y_test))</span>
<span id="cb14-2"><a href="deep-learning.html#cb14-2"></a><span class="co">##     loss accuracy </span></span>
<span id="cb14-3"><a href="deep-learning.html#cb14-3"></a><span class="co">## 0.299382 0.881520</span></span></code></pre></div>
<p><strong>Predicted probability of “positive” for the first <span class="math inline">\(10\)</span> test data</strong></p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="deep-learning.html#cb15-1"></a>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">predict</span>(x_test[<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>,])</span>
<span id="cb15-2"><a href="deep-learning.html#cb15-2"></a><span class="co">##              [,1]</span></span>
<span id="cb15-3"><a href="deep-learning.html#cb15-3"></a><span class="co">##  [1,] 0.145351708</span></span>
<span id="cb15-4"><a href="deep-learning.html#cb15-4"></a><span class="co">##  [2,] 0.998798728</span></span>
<span id="cb15-5"><a href="deep-learning.html#cb15-5"></a><span class="co">##  [3,] 0.757797539</span></span>
<span id="cb15-6"><a href="deep-learning.html#cb15-6"></a><span class="co">##  [4,] 0.753620028</span></span>
<span id="cb15-7"><a href="deep-learning.html#cb15-7"></a><span class="co">##  [5,] 0.943060100</span></span>
<span id="cb15-8"><a href="deep-learning.html#cb15-8"></a><span class="co">##  [6,] 0.715207398</span></span>
<span id="cb15-9"><a href="deep-learning.html#cb15-9"></a><span class="co">##  [7,] 0.999003470</span></span>
<span id="cb15-10"><a href="deep-learning.html#cb15-10"></a><span class="co">##  [8,] 0.005008941</span></span>
<span id="cb15-11"><a href="deep-learning.html#cb15-11"></a><span class="co">##  [9,] 0.956825435</span></span>
<span id="cb15-12"><a href="deep-learning.html#cb15-12"></a><span class="co">## [10,] 0.986143529</span></span></code></pre></div>
</div>
<div id="multiclass-classification" class="section level2 hasAnchor">
<h2><span class="header-section-number">20.7</span> Multiclass Classification<a href="deep-learning.html#multiclass-classification" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Classifying news wires by topic</p>
</div>
<div id="regression" class="section level2 hasAnchor">
<h2><span class="header-section-number">20.8</span> Regression<a href="deep-learning.html#regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Estimating the price of a house, given real-estate data</p>
</div>
<div id="appendix" class="section level2 hasAnchor">
<h2><span class="header-section-number">20.9</span> Appendix<a href="deep-learning.html#appendix" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>To decode the text in <code>imdb</code>:</p>
<p>You can decode the data using the following code:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="deep-learning.html#cb16-1"></a><span class="co"># word_index is a dictionary mapping words to an integer index</span></span>
<span id="cb16-2"><a href="deep-learning.html#cb16-2"></a>word_index &lt;-<span class="st"> </span><span class="kw">dataset_imdb_word_index</span>()</span>
<span id="cb16-3"><a href="deep-learning.html#cb16-3"></a><span class="co"># We reverse it, mapping integer indices to words</span></span>
<span id="cb16-4"><a href="deep-learning.html#cb16-4"></a>reverse_word_index &lt;-<span class="st"> </span><span class="kw">names</span>(word_index)</span>
<span id="cb16-5"><a href="deep-learning.html#cb16-5"></a><span class="kw">names</span>(reverse_word_index) &lt;-<span class="st"> </span>word_index</span>
<span id="cb16-6"><a href="deep-learning.html#cb16-6"></a><span class="co"># We decode the review; note that our indices were offset by 3</span></span>
<span id="cb16-7"><a href="deep-learning.html#cb16-7"></a><span class="co"># because 0, 1 and 2 are reserved indices for &quot;padding&quot;, &quot;start of sequence&quot;, and &quot;unknown&quot;.</span></span>
<span id="cb16-8"><a href="deep-learning.html#cb16-8"></a>decoded_review &lt;-<span class="st"> </span><span class="kw">sapply</span>(train_data[[<span class="dv">1</span>]], <span class="cf">function</span>(index) {</span>
<span id="cb16-9"><a href="deep-learning.html#cb16-9"></a>  word &lt;-<span class="st"> </span><span class="cf">if</span> (index <span class="op">&gt;=</span><span class="st"> </span><span class="dv">3</span>) reverse_word_index[[<span class="kw">as.character</span>(index <span class="op">-</span><span class="st"> </span><span class="dv">3</span>)]]</span>
<span id="cb16-10"><a href="deep-learning.html#cb16-10"></a>  <span class="cf">if</span> (<span class="op">!</span><span class="kw">is.null</span>(word)) word <span class="cf">else</span> <span class="st">&quot;?&quot;</span></span>
<span id="cb16-11"><a href="deep-learning.html#cb16-11"></a>})</span>
<span id="cb16-12"><a href="deep-learning.html#cb16-12"></a></span>
<span id="cb16-13"><a href="deep-learning.html#cb16-13"></a><span class="kw">cat</span>(decoded_review)</span>
<span id="cb16-14"><a href="deep-learning.html#cb16-14"></a><span class="co">## ? this film was just brilliant casting location scenery story direction everyone&#39;s really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy&#39;s that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don&#39;t you think the whole story was so lovely because it was true and was someone&#39;s life after all that was shared with us all</span></span></code></pre></div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ensemble-methods.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Book.pdf", "Book.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
